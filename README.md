The primary goal of this project is to build a classifier for speech emotion recognition and explore different input representations/features of speech that improve the classifier's performance. Additionally, the project will involve an ablation study to analyze how a classifier trained on one language performs on different languages for emotional classification. Finally, an application utilizing the trained emotional classifier will be developed, such as a personalized music recommendation system based on emotions.
